#!/usr/bin/env python3
"""
RWA-HUB 5.0 æ•°æ®åº“å¥åº·æ£€æŸ¥è„šæœ¬
å®šæœŸæ‰§è¡Œä»¥ç›‘æ§æ•°æ®åº“æ€§èƒ½å’Œæ•°æ®å®Œæ•´æ€§
"""

import psycopg2
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Tuple

# æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'host': 'localhost',
    'database': 'rwa_hub',
    'user': 'rwa_hub_user',
    'password': 'password',
    'port': 5432
}

class DatabaseHealthChecker:
    def __init__(self, config: Dict):
        self.config = config
        self.conn = None
        
    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.conn = psycopg2.connect(**self.config)
            return True
        except Exception as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False
    
    def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        if self.conn:
            self.conn.close()
    
    def execute_query(self, query: str, params: tuple = None) -> List[Tuple]:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        cursor = self.conn.cursor()
        cursor.execute(query, params)
        return cursor.fetchall()
    
    def check_table_sizes(self):
        """æ£€æŸ¥è¡¨å¤§å°"""
        print("ğŸ“Š è¡¨å¤§å°ç»Ÿè®¡:")
        print("-" * 50)
        
        query = """
        SELECT 
            schemaname as schema,
            tablename as table,
            pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
            pg_stat_get_tuples_inserted(c.oid) as inserts,
            pg_stat_get_tuples_updated(c.oid) as updates,
            pg_stat_get_tuples_deleted(c.oid) as deletes
        FROM pg_tables pt
        LEFT JOIN pg_class c ON c.relname = pt.tablename
        WHERE schemaname = 'public'
        ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
        LIMIT 10;
        """
        
        results = self.execute_query(query)
        for row in results:
            print(f"  {row[1]:<20} | {row[2]:<10} | I:{row[3]} U:{row[4]} D:{row[5]}")
    
    def check_index_usage(self):
        """æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ"""
        print("\nğŸ” ç´¢å¼•ä½¿ç”¨ç»Ÿè®¡:")
        print("-" * 50)
        
        query = """
        SELECT 
            schemaname,
            tablename,
            indexname,
            idx_tup_read,
            idx_tup_fetch,
            idx_scan
        FROM pg_stat_user_indexes
        WHERE idx_scan < 10  -- ä½¿ç”¨æ¬¡æ•°å°‘äº10çš„ç´¢å¼•
        ORDER BY idx_scan ASC;
        """
        
        results = self.execute_query(query)
        if results:
            print("âš ï¸  ä½¿ç”¨ç‡è¾ƒä½çš„ç´¢å¼•:")
            for row in results:
                print(f"  {row[1]}.{row[2]} - æ‰«ææ¬¡æ•°: {row[5]}")
        else:
            print("âœ… æ‰€æœ‰ç´¢å¼•ä½¿ç”¨ç‡è‰¯å¥½")
    
    def check_slow_queries(self):
        """æ£€æŸ¥æ…¢æŸ¥è¯¢"""
        print("\nâ±ï¸  æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡:")
        print("-" * 50)
        
        # æ£€æŸ¥pg_stat_statementsæ˜¯å¦å­˜åœ¨
        check_extension = """
        SELECT EXISTS (
            SELECT 1 FROM pg_extension WHERE extname = 'pg_stat_statements'
        );
        """
        
        has_extension = self.execute_query(check_extension)[0][0]
        
        if has_extension:
            query = """
            SELECT 
                query,
                calls,
                mean_time,
                total_time
            FROM pg_stat_statements
            WHERE mean_time > 100  -- å¹³å‡æ‰§è¡Œæ—¶é—´è¶…è¿‡100ms
            ORDER BY mean_time DESC
            LIMIT 5;
            """
            results = self.execute_query(query)
            if results:
                for row in results:
                    print(f"  æŸ¥è¯¢: {row[0][:50]}...")
                    print(f"    è°ƒç”¨æ¬¡æ•°: {row[1]}, å¹³å‡æ—¶é—´: {row[2]:.2f}ms")
            else:
                print("âœ… æ²¡æœ‰å‘ç°æ…¢æŸ¥è¯¢")
        else:
            print("â„¹ï¸  pg_stat_statements æ‰©å±•æœªå®‰è£…ï¼Œæ— æ³•æ£€æŸ¥æ…¢æŸ¥è¯¢")
    
    def check_data_consistency(self):
        """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§"""
        print("\nğŸ”§ æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥:")
        print("-" * 50)
        
        checks = [
            {
                'name': 'remaining_supply ä¸ºè´Ÿå€¼',
                'query': 'SELECT COUNT(*) FROM assets WHERE remaining_supply < 0',
                'expected': 0
            },
            {
                'name': 'remaining_supply è¶…è¿‡ token_supply',
                'query': 'SELECT COUNT(*) FROM assets WHERE remaining_supply > token_supply',
                'expected': 0
            },
            {
                'name': 'äº¤æ˜“é‡‘é¢ä¸ºè´Ÿå€¼',
                'query': 'SELECT COUNT(*) FROM trades WHERE amount <= 0 OR price < 0',
                'expected': 0
            },
            {
                'name': 'å­¤ç«‹çš„ä½£é‡‘è®°å½•',
                'query': '''SELECT COUNT(*) FROM commission_records cr 
                           LEFT JOIN trades t ON cr.transaction_id = t.id 
                           WHERE t.id IS NULL''',
                'expected': 0
            },
            {
                'name': 'æ— æ•ˆçš„èµ„äº§çŠ¶æ€',
                'query': 'SELECT COUNT(*) FROM assets WHERE status NOT IN (1,2,3,4,5,6,7,8)',
                'expected': 0
            }
        ]
        
        for check in checks:
            result = self.execute_query(check['query'])[0][0]
            status = "âœ…" if result == check['expected'] else "âŒ"
            print(f"  {status} {check['name']}: {result}")
    
    def check_recent_activity(self):
        """æ£€æŸ¥æœ€è¿‘æ´»åŠ¨"""
        print("\nğŸ“ˆ æœ€è¿‘æ´»åŠ¨ç»Ÿè®¡:")
        print("-" * 50)
        
        # æœ€è¿‘24å°æ—¶çš„æ´»åŠ¨
        yesterday = datetime.now() - timedelta(days=1)
        
        queries = [
            ('æ–°å¢èµ„äº§', 'SELECT COUNT(*) FROM assets WHERE created_at >= %s', (yesterday,)),
            ('æ–°å¢äº¤æ˜“', 'SELECT COUNT(*) FROM trades WHERE created_at >= %s', (yesterday,)),
            ('å®Œæˆäº¤æ˜“', 'SELECT COUNT(*) FROM trades WHERE status = \'completed\' AND created_at >= %s', (yesterday,)),
            ('æ–°å¢ç”¨æˆ·', 'SELECT COUNT(*) FROM users WHERE created_at >= %s', (yesterday,)),
        ]
        
        for name, query, params in queries:
            result = self.execute_query(query, params)[0][0]
            print(f"  {name} (24h): {result}")
    
    def check_database_locks(self):
        """æ£€æŸ¥æ•°æ®åº“é”"""
        print("\nğŸ”’ æ•°æ®åº“é”çŠ¶æ€:")
        print("-" * 50)
        
        query = """
        SELECT 
            pg_class.relname,
            pg_locks.locktype,
            pg_locks.mode,
            pg_locks.granted
        FROM pg_locks
        JOIN pg_class ON pg_locks.relation = pg_class.oid
        WHERE NOT pg_locks.granted;
        """
        
        results = self.execute_query(query)
        if results:
            print("âš ï¸  å‘ç°æœªæˆäºˆçš„é”:")
            for row in results:
                print(f"  è¡¨: {row[0]}, é”ç±»å‹: {row[1]}, æ¨¡å¼: {row[2]}")
        else:
            print("âœ… æ²¡æœ‰å‘ç°é˜»å¡çš„é”")
    
    def generate_optimization_suggestions(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        print("-" * 50)
        
        suggestions = []
        
        # æ£€æŸ¥ç¼ºå¤±çš„ç´¢å¼•
        missing_indexes = """
        SELECT 
            schemaname, tablename, attname, n_distinct, correlation
        FROM pg_stats 
        WHERE schemaname = 'public' 
        AND n_distinct > 100 
        AND tablename IN ('assets', 'trades', 'users', 'commission_records')
        AND attname NOT IN (
            SELECT column_name 
            FROM information_schema.statistics 
            WHERE table_schema = 'public'
        );
        """
        
        # æ£€æŸ¥è¡¨è†¨èƒ€
        bloat_query = """
        SELECT 
            schemaname, tablename,
            pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
        FROM pg_tables 
        WHERE schemaname = 'public'
        ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
        """
        
        results = self.execute_query(bloat_query)
        large_tables = [row for row in results if 'MB' in row[2] or 'GB' in row[2]]
        
        if large_tables:
            suggestions.append("è€ƒè™‘å¯¹å¤§è¡¨è¿›è¡ŒVACUUMå’ŒREINDEXæ“ä½œ")
        
        suggestions.extend([
            "å®šæœŸæ‰§è¡ŒANALYZEæ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯",
            "ç›‘æ§æ…¢æŸ¥è¯¢æ—¥å¿—",
            "è€ƒè™‘åˆ†åŒºå¤§è¡¨ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½",
            "å®šæœŸå¤‡ä»½æ•°æ®åº“",
            "ç›‘æ§ç£ç›˜ç©ºé—´ä½¿ç”¨æƒ…å†µ"
        ])
        
        for i, suggestion in enumerate(suggestions, 1):
            print(f"  {i}. {suggestion}")
    
    def run_full_check(self):
        """è¿è¡Œå®Œæ•´çš„å¥åº·æ£€æŸ¥"""
        print("ğŸ¥ RWA-HUB 5.0 æ•°æ®åº“å¥åº·æ£€æŸ¥æŠ¥å‘Š")
        print("=" * 60)
        print(f"æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)
        
        if not self.connect():
            return
        
        try:
            self.check_table_sizes()
            self.check_index_usage()
            self.check_slow_queries()
            self.check_data_consistency()
            self.check_recent_activity()
            self.check_database_locks()
            self.generate_optimization_suggestions()
            
        except Exception as e:
            print(f"âŒ æ£€æŸ¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        finally:
            self.disconnect()
        
        print("\n" + "=" * 60)
        print("âœ… å¥åº·æ£€æŸ¥å®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    checker = DatabaseHealthChecker(DB_CONFIG)
    checker.run_full_check()

if __name__ == "__main__":
    main()
